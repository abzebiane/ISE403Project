@article{molchanov2017,
  title={Pruning convolutional neural networks for resource efficient inference},
  author={Molchanov, Pavlo and Tyree, Stephen and Karras, Tero and Aila, Timo and Kautz, Jan},
  journal={arXiv preprint arXiv:1611.06440},
  year={2016}
}

@inproceedings{liu2017,
  title={Learning efficient convolutional networks through network slimming},
  author={Liu, Zhuang and Li, Jianguo and Shen, Zhiqiang and Huang, Gao and Yan, Shoumeng and Zhang, Changshui},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2736--2744},
  year={2017}
}

@inproceedings{bui2024,
  title={A proximal algorithm for network slimming},
  author={Bui, Kevin and Xue, Fanghui and Park, Fredrick and Qi, Yingyong and Xin, Jack},
  booktitle={International Conference on Machine Learning, Optimization, and Data Science},
  pages={69--83},
  year={2023},
  organization={Springer}
}

@article{han2015,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={arXiv preprint arXiv:1510.00149},
  year={2015}
}

